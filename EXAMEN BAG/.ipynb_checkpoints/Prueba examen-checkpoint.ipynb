{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3acfeb",
   "metadata": {},
   "source": [
    "# EXAMEN BAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c8d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jose\n",
      "[nltk_data]     Julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer\n",
    "print(\" \".join(SnowballStemmer.languages)) \n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bd4a3",
   "metadata": {},
   "source": [
    "EJERCICIO 1. Recopilación de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ccb8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Tweets.csv', usecols = [\"text\"])\n",
    "d = data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d6ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "1      Sooo SAD I will miss you here in San Diego!!!\n",
      "2                          my boss is bullying me...\n",
      "3                     what interview! leave me alone\n",
      "4   Sons of ****, why couldn`t they put them on t...\n",
      "                                                text\n",
      "1      Sooo SAD I will miss you here in San Diego!!!\n",
      "2                          my boss is bullying me...\n",
      "3                     what interview! leave me alone\n",
      "4   Sons of ****, why couldn`t they put them on t...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1      Sooo SAD I will miss you here in San Diego!!!\n",
       "2                          my boss is bullying me...\n",
       "3                     what interview! leave me alone\n",
       "4   Sons of ****, why couldn`t they put them on t..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('Tweets.csv')\n",
    "data3 = data2[['text']]\n",
    "#data = data[\"text\"]\n",
    "\n",
    "d3 = data3[1:5]\n",
    "print(data3[1:5])\n",
    "print(d)\n",
    "d\n",
    "#tknzr.tokenize_sents(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef731f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                    I`d have responded, if I were going\n",
       "1          Sooo SAD I will miss you here in San Diego!!!\n",
       "2                              my boss is bullying me...\n",
       "3                         what interview! leave me alone\n",
       "4       Sons of ****, why couldn`t they put them on t...\n",
       "...                                                  ...\n",
       "27476   wish we could come see u on Denver  husband l...\n",
       "27477   I`ve wondered about rake to.  The client has ...\n",
       "27478   Yay good for both of you. Enjoy the break - y...\n",
       "27479                         But it was worth it  ****.\n",
       "27480     All this flirting going on - The ATG smiles...\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data2 = pd.read_csv('Tweets.csv')\n",
    "data3 = data2[['text']]\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1481b55",
   "metadata": {},
   "source": [
    "EJERCICIO 2. Limpieza del texto, eliminar palabras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3e919",
   "metadata": {},
   "source": [
    "La diferencia principal entre word_tokenize y TweetTokenizer en NLTK radica en cómo manejan ciertos patrones de tokenización, especialmente en el contexto de las redes sociales y los textos informales como tweets.\n",
    "\n",
    "word_tokenize:\n",
    "Divide el texto en palabras y signos de puntuación.\n",
    "Trata \"cannot\" como \"can\" y \"not\", dividiendo la palabra en dos tokens (\"can\" y \"not\").\n",
    "Es más general y se utiliza para texto en general.\n",
    "\n",
    "TweetTokenizer:\n",
    "Especificamente diseñado para manejar tokens en tweets y otros textos informales.\n",
    "Mantiene \"cannot\" como una sola palabra (\"cannot\").\n",
    "Reconoce emoticonos y maneja algunas convenciones específicas de los tweets, como hashtags y menciones.\n",
    "\n",
    "En resumen, TweetTokenizer está diseñado para trabajar mejor con texto de redes sociales y texto informal, mientras que word_tokenize es más general y puede dividir ciertas palabras de manera diferente. La elección entre ellos depende del tipo de texto con el que estés trabajando y de cómo quieras que se manejen ciertos patrones específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9945c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', 'not', 'can', 'not', 'work', 'under', 'these', 'conditions', '!']\n",
      "['I', 'cannot', 'cannot', 'work', 'under', 'these', 'conditions', '!']\n",
      "I cannot wait to see you @gloari, #queso http//hola I cannot wait to see you ,  \n",
      "hola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Jose\n",
      "[nltk_data]     Julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "s4 = \"I cannot cannot work under these conditions!\"\n",
    "print(word_tokenize(s4))\n",
    "print(TweetTokenizer().tokenize(s4))\n",
    "\n",
    "\n",
    "import re\n",
    "s1 = \"I cannot wait to see you @gloari, #queso http//hola\"\n",
    "texto_procesado = re.sub(r'(@\\w+|#\\w+|http\\S+)', '', s1)\n",
    "print(s1, texto_procesado)\n",
    "\n",
    "\n",
    "s2 = \"HOLA\"\n",
    "print(s2.lower())\n",
    "\n",
    "s3 = 1.73\n",
    "type(s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4e0229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.tokenize.casual.TweetTokenizer object at 0x0000020FE6B93250>\n"
     ]
    }
   ],
   "source": [
    "s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "print(TweetTokenizer(s0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2aa8fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cooool',\n",
       " '#dummysmiley',\n",
       " ':',\n",
       " ':-)',\n",
       " ':-P',\n",
       " '<3',\n",
       " 'and',\n",
       " 'some',\n",
       " 'arrows',\n",
       " '<',\n",
       " '>',\n",
       " '->',\n",
       " '<--']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "tknzr.tokenize(s0)\n",
    "#TweetTokenizer().tokenize(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e6f011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1050676386.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    if pd.isna(texto):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def float_texto(dataset):\n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        if type(texto) == str:\n",
    "            print(texto)\n",
    "\n",
    "float_texto(data)\n",
    "        \n",
    "    \n",
    "    if pd.isna(texto):\n",
    "            # Verificar si el valor es NaN\n",
    "            print(\"NaN\")\n",
    "            print(fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56abec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "# stop = stopwords.words('english')\n",
    "\n",
    "#print(stop, stop_words)\n",
    "stemmer = SnowballStemmer(language = 'english')\n",
    "# from nltk.stem.snowball import GermanStemmer\n",
    "# stemmer = GermanStemmer()\n",
    "\n",
    "s5 = \"cared and fairly playing football\"\n",
    "s5 = tknzr.tokenize(s5)\n",
    "#print(stemmer.stem(s5[3]))\n",
    "\n",
    "\n",
    "print(data[:10])\n",
    "\n",
    "def prueba_stop(dataset):\n",
    "    #dataset = dataset.astype(str)\n",
    "    tknzr = TweetTokenizer()\n",
    "    import_words = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        texto_procesado = re.sub(r'(@\\w+|#\\w+|http\\S+)', '', texto)\n",
    "        texto_procesado = texto_procesado.lower()\n",
    "        texto_procesado = tknzr.tokenize(texto_procesado)\n",
    "        #print(texto)\n",
    "        for word in texto_procesado:\n",
    "            if word not in stop_words:\n",
    "                import_words.append(word)\n",
    "    print(import_words)\n",
    "\n",
    "\n",
    "prueba_stop(data[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cd24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[:10])\n",
    "\n",
    "def limpiar_texto(dataset):\n",
    "    dataset = dataset.astype(str)   # para asegurarnos de que todas las filas son cadenas y no otro tipo de dato\n",
    "    tknzr = TweetTokenizer()\n",
    "    stemmer = SnowballStemmer(language = 'english')\n",
    "    stem_words = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        texto_procesado = re.sub(r'(@\\w+|#\\w+|http\\S+)', '', texto)\n",
    "        texto_procesado = texto_procesado.lower()\n",
    "        texto_procesado = tknzr.tokenize(texto_procesado)\n",
    "        stem_words = [stemmer.stem(word) for word in texto_procesado if word not in stop_words]\n",
    "        final_text = ' '.join(stem_words)\n",
    "        dataset.loc[indice, 'text'] = final_text\n",
    "\n",
    "    return dataset\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ab1d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boss bulli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview ! leav alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son * * * , ` put releas alreadi bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text\n",
       "1            sooo sad miss san diego ! ! !\n",
       "2                           boss bulli ...\n",
       "3                    interview ! leav alon\n",
       "4  son * * * , ` put releas alreadi bought"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_texto(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7575d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1      Sooo SAD I will miss you here in San Diego!!!\n",
       "2                          my boss is bullying me...\n",
       "3                     what interview! leave me alone\n",
       "4   Sons of ****, why couldn`t they put them on t..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba70c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto3(dataset):\n",
    "    dataset = dataset.astype(str)\n",
    "    tknzr = TweetTokenizer()\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        texto_procesado = re.sub(r'(@\\w+|#\\w+|http\\S+)', '', texto)\n",
    "        texto_procesado = texto_procesado.lower()\n",
    "        texto_procesado = tknzr.tokenize(texto_procesado)\n",
    "\n",
    "        # Inicializar la lista de stem_words para cada fila\n",
    "        stem_words = []\n",
    "\n",
    "        for word in texto_procesado:\n",
    "            # Utilizar expresión condicional completa\n",
    "            stem_words.append(stemmer.stem(word) if word not in stop_words else word)\n",
    "\n",
    "        final_text = ' '.join(stem_words)\n",
    "        dataset.at[indice, 'text'] = final_text\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96927e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ` d have respond , if i were go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad i will miss you here in san diego ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bulli me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview ! leav me alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son of * * * , why couldn ` t they put them on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on denver husband los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>i ` ve wonder about rake to . the client has m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good for both of you . enjoy the break - y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>but it was worth it * * * .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>all this flirt go on - the atg smile . yay . (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                      i ` d have respond , if i were go\n",
       "1       sooo sad i will miss you here in san diego ! ! !\n",
       "2                                my boss is bulli me ...\n",
       "3                          what interview ! leav me alon\n",
       "4      son of * * * , why couldn ` t they put them on...\n",
       "...                                                  ...\n",
       "27476  wish we could come see u on denver husband los...\n",
       "27477  i ` ve wonder about rake to . the client has m...\n",
       "27478  yay good for both of you . enjoy the break - y...\n",
       "27479                        but it was worth it * * * .\n",
       "27480  all this flirt go on - the atg smile . yay . (...\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_texto3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d6e63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                    I`d have responded, if I were going\n",
       "1          Sooo SAD I will miss you here in San Diego!!!\n",
       "2                              my boss is bullying me...\n",
       "3                         what interview! leave me alone\n",
       "4       Sons of ****, why couldn`t they put them on t...\n",
       "...                                                  ...\n",
       "27476   wish we could come see u on Denver  husband l...\n",
       "27477   I`ve wondered about rake to.  The client has ...\n",
       "27478   Yay good for both of you. Enjoy the break - y...\n",
       "27479                         But it was worth it  ****.\n",
       "27480     All this flirting going on - The ATG smiles...\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45de89",
   "metadata": {},
   "source": [
    "Dentro de la función TweetTokenizer() tenemos opciones para hacer casi todo lo que nos piden con argumentos de ella misma, por lo que el código estará más depurado. \n",
    "    - reduce_len= True  <- repeated character seq of 3+ to just 3. \n",
    "    - strip_handles = True <- remove Twitter handles such as usernames.\n",
    "    - preserve_case = False <- uppercase tokens to lowercase ones. Emoticons not affected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto2(dataset):\n",
    "    dataset = dataset.astype(str)   # para asegurarnos de que todas las filas son cadenas y no otro tipo de dato\n",
    "    tknzr = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        texto_procesado = tknzr.tokenize(texto)\n",
    "        print(texto_procesado)\n",
    "    \n",
    "limpiar_texto2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa8833a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                    I`d have responded, if I were going\n",
       "1          Sooo SAD I will miss you here in San Diego!!!\n",
       "2                              my boss is bullying me...\n",
       "3                         what interview! leave me alone\n",
       "4       Sons of ****, why couldn`t they put them on t...\n",
       "...                                                  ...\n",
       "27476   wish we could come see u on Denver  husband l...\n",
       "27477   I`ve wondered about rake to.  The client has ...\n",
       "27478   Yay good for both of you. Enjoy the break - y...\n",
       "27479                         But it was worth it  ****.\n",
       "27480     All this flirting going on - The ATG smiles...\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8e93ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>` respond , go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boss bulli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview ! leav alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son * * * , ` put releas alreadi bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish could come see u denver husband lost job ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>` wonder rake . client made clear . net , ` fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good . enjoy break - probabl need hectic w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>worth * * * .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>flirt go - atg smile . yay . ( ( hug ) )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                         ` respond , go\n",
       "1                          sooo sad miss san diego ! ! !\n",
       "2                                         boss bulli ...\n",
       "3                                  interview ! leav alon\n",
       "4                son * * * , ` put releas alreadi bought\n",
       "...                                                  ...\n",
       "27476  wish could come see u denver husband lost job ...\n",
       "27477  ` wonder rake . client made clear . net , ` fo...\n",
       "27478  yay good . enjoy break - probabl need hectic w...\n",
       "27479                                      worth * * * .\n",
       "27480           flirt go - atg smile . yay . ( ( hug ) )\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def limpiar_textodef(dataset):\n",
    "    dataset['text'] = dataset['text'].astype(str)\n",
    "    \n",
    "    # Inicializar el tokenizador de tweets y el stemmer\n",
    "    tokenizer = TweetTokenizer(preserve_case = False)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    # Obtener la lista de stop words en inglés\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Iterar sobre cada fila del DataFrame\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Obtener el texto de la fila\n",
    "        texto = row['text']\n",
    "        \n",
    "        # Eliminar menciones, hashtags y URLs\n",
    "        texto_procesado = re.sub(r'@[^\\s]+|#[^\\s]+|http[^\\s]+|www[^\\s]+', '', texto)\n",
    "        \n",
    "        # Convertir a minúsculas\n",
    "        #texto = texto.lower()\n",
    "        \n",
    "        # Tokenización\n",
    "        tokens = tokenizer.tokenize(texto)\n",
    "        \n",
    "        # Eliminar stop words y aplicar lematización (stemming)\n",
    "        tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "        \n",
    "        # Unir las palabras en una cadena separada por espacios\n",
    "        final_text = ' '.join(tokens)\n",
    "        \n",
    "        # Reemplazar el texto original en el DataFrame\n",
    "        dataset.at[index, 'text'] = final_text\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Cargar datos\n",
    "data = pd.read_csv('Tweets.csv', usecols=[\"text\"])\n",
    "d = data[1:5]\n",
    "\n",
    "# Aplicar la función de limpieza\n",
    "limpiar_textodef(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "693ea2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>` respond , go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boss bulli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview ! leav alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son * * * , ` put releas alreadi bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish could come see u denver husband lost job ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>` wonder rake . client made clear . net , ` fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good . enjoy break - probabl need hectic w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>worth * * * .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>flirt go - atg smile . yay . ( ( hug ) )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                         ` respond , go\n",
       "1                          sooo sad miss san diego ! ! !\n",
       "2                                         boss bulli ...\n",
       "3                                  interview ! leav alon\n",
       "4                son * * * , ` put releas alreadi bought\n",
       "...                                                  ...\n",
       "27476  wish could come see u denver husband lost job ...\n",
       "27477  ` wonder rake . client made clear . net , ` fo...\n",
       "27478  yay good . enjoy break - probabl need hectic w...\n",
       "27479                                      worth * * * .\n",
       "27480           flirt go - atg smile . yay . ( ( hug ) )\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63bfa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')\n",
    "tweets=tweets[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cc58a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_textovicente(dataset):\n",
    "    dataset = dataset.astype(str)\n",
    "    for n in range(0,len(dataset)-1):\n",
    "        texto_limpio = re.sub(r\"@\\w+|#\\w+|https?://\\S+|www\\.\\S+\",\"\",dataset[n])\n",
    "        texto_minusculas = texto_limpio.lower()\n",
    "        tokenizer = TweetTokenizer()\n",
    "        texto_separado = tokenizer.tokenize(texto_minusculas)\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        texto_filtrado = []\n",
    "        for palabra in texto_separado:\n",
    "            if palabra not in stop_words:\n",
    "                texto_filtrado.append(palabra)\n",
    "            \n",
    "            lematizacion = SnowballStemmer(\"english\")\n",
    "            lexemas = [lematizacion.stem(palabra) for palabra in texto_filtrado]\n",
    "        \n",
    "        texto_final = \" \".join(lexemas)\n",
    "        dataset[n]=texto_final\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c6625b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m limpiar_textovicente(d)\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mlimpiar_textovicente\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     texto_limpio \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|https?://\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+|www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,dataset[n])\n\u001b[0;32m      5\u001b[0m     texto_minusculas \u001b[38;5;241m=\u001b[39m texto_limpio\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m TweetTokenizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "limpiar_textovicente(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b37eb",
   "metadata": {},
   "source": [
    "EJERCICIO 3. Etiquetado de datos con herramientas ya \n",
    "existentes. (2p)\n",
    "Define una función llamada clasificador que toma el dataset con el texto procesado y limpio \n",
    "como entrada. El resultado de este proceso debe almacenarse en un archivo CSV con dos columnas:\n",
    "una para la frase o texto y otra para la etiqueta correspondiente.\n",
    "\n",
    "➢ Para cada línea de texto del data set, la función debe:\n",
    "\n",
    "    ➢ Utilizar el modelo TextBlob para realizar un análisis de sentimiento. Investiga cómo hacerlo.\n",
    "\n",
    "    ➢ En función de la polaridad calculada, clasificar el sentimiento en categorías específicas. Las categorías deben incluir \"Contento\", \"Muy feliz\", \"Neutro\", \"Molesto\" y \"Hater\".\n",
    "\n",
    "➢ Finalmente, guardar los resultados como una columna nueva en el dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "433a4254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0) Sentiment(polarity=-0.8, subjectivity=0.9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>much love hope , reckon chanc minim =p ` never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>realli realli like song love stori taylor swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sharpi run danger low ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>want go music tonight lost voic .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test test lg env 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>uh oh , sunburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>` ok , tri plot altern speak * sigh *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>` sick past day thus , hair look wierd . didnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>back home gonna miss everi one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oh mar , ` sorri ! ! hope find soon ! ! &lt;3 &lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>play ghost onlin realli interest . new updat k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clean hous famili com later today ..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "10  much love hope , reckon chanc minim =p ` never...\n",
       "11    realli realli like song love stori taylor swift\n",
       "12                          sharpi run danger low ink\n",
       "13                  want go music tonight lost voic .\n",
       "14                                 test test lg env 2\n",
       "15                                    uh oh , sunburn\n",
       "16              ` ok , tri plot altern speak * sigh *\n",
       "17  ` sick past day thus , hair look wierd . didnt...\n",
       "18                     back home gonna miss everi one\n",
       "19                                                hes\n",
       "20      oh mar , ` sorri ! ! hope find soon ! ! <3 <3\n",
       "21  play ghost onlin realli interest . new updat k...\n",
       "22               clean hous famili com later today .."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Ejemplo de texto\n",
    "texto = \"you are a prostitute\"\n",
    "texto1 = \"i hate you a lot, i want to kill you, murder you, commit war crimes,suicide, kill myself and all my family, kill babies\"\n",
    "# Crear un objeto TextBlob\n",
    "blob = TextBlob(texto)\n",
    "blob1 = TextBlob(texto1)\n",
    "\n",
    "# Analizar el sentimiento\n",
    "sentimiento = blob.sentiment\n",
    "sentimiento1 = blob1.sentiment\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(sentimiento, sentimiento1)\n",
    "\n",
    "\n",
    "data[10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04c08ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador(dataset):\n",
    "    sentiments = []\n",
    "    for indice, fila in dataset.iterrows():\n",
    "        texto = fila['text']\n",
    "        blob = TextBlob(texto)\n",
    "        sentiments.append(blob.sentiment)\n",
    "    return sentiments\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2618f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text\n",
      "0                                         ` respond , go\n",
      "1                          sooo sad miss san diego ! ! !\n",
      "2                                         boss bulli ...\n",
      "3                                  interview ! leav alon\n",
      "4                 son * * * , ` put relea alreadi bought\n",
      "...                                                  ...\n",
      "27476  wish could come see u denver husband lost job ...\n",
      "27477  ` wonder rake . client made clear . net , ` fo...\n",
      "27478  yay good . enjoy break - probabl need hectic w...\n",
      "27479                                      worth * * * .\n",
      "27480           flirt go - atg smile . yay . ( ( hug ) )\n",
      "\n",
      "[27481 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.9765625, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.3, subjectivity=0.15000000000000002),\n",
       " Sentiment(polarity=0.16, subjectivity=0.5399999999999999),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.125, subjectivity=1.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.48214285714285715, subjectivity=0.5535714285714286),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=1.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.06818181818181818, subjectivity=0.22727272727272727),\n",
       " Sentiment(polarity=0.18333333333333335, subjectivity=0.35000000000000003),\n",
       " Sentiment(polarity=0.4, subjectivity=0.3666666666666667),\n",
       " Sentiment(polarity=-0.3125, subjectivity=0.6875),\n",
       " Sentiment(polarity=0.35, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.30000000000000004),\n",
       " Sentiment(polarity=0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.35),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.08806818181818182, subjectivity=0.375),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=0.4666666666666666, subjectivity=0.6333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=0.375, subjectivity=0.8),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.19999999999999993, subjectivity=0.43333333333333335),\n",
       " Sentiment(polarity=0.5625, subjectivity=0.6),\n",
       " Sentiment(polarity=0.1, subjectivity=0.2),\n",
       " Sentiment(polarity=-0.359375, subjectivity=0.5875),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.2, subjectivity=0.4),\n",
       " Sentiment(polarity=0.06818181818181818, subjectivity=0.2606060606060606),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.25),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.275, subjectivity=0.375),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.2857142857142857, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5666666666666668, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.5),\n",
       " Sentiment(polarity=0.875, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.25, subjectivity=0.25),\n",
       " Sentiment(polarity=0.1, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.7142857142857143, subjectivity=0.8571428571428571),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.5),\n",
       " Sentiment(polarity=0.05000000000000002, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.43714285714285717, subjectivity=0.5471428571428572),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.1621212121212121, subjectivity=0.39040404040404036),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=-0.15625, subjectivity=0.15833333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.06818181818181818, subjectivity=0.22727272727272727),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.21428571428571427, subjectivity=0.5714285714285714),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=-0.46875, subjectivity=0.4),\n",
       " Sentiment(polarity=0.09166666666666666, subjectivity=0.5416666666666667),\n",
       " Sentiment(polarity=0.26666666666666666, subjectivity=0.6),\n",
       " Sentiment(polarity=0.15, subjectivity=0.45),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4625, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1875),\n",
       " Sentiment(polarity=0.3, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.75),\n",
       " Sentiment(polarity=0.5333333333333333, subjectivity=0.6500000000000001),\n",
       " Sentiment(polarity=0.55, subjectivity=0.8),\n",
       " Sentiment(polarity=0.7, subjectivity=0.9),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.675, subjectivity=1.0),\n",
       " Sentiment(polarity=0.1, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.11666666666666665, subjectivity=0.3055555555555555),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.55),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.7666666666666666, subjectivity=0.5666666666666667),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.6),\n",
       " Sentiment(polarity=0.17045454545454544, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=-0.30000000000000004, subjectivity=0.55),\n",
       " Sentiment(polarity=0.2604166666666667, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=-0.3499999999999999, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4375, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=0.3875, subjectivity=0.30000000000000004),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=1.0, subjectivity=0.75),\n",
       " Sentiment(polarity=0.15625, subjectivity=0.21666666666666667),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=-0.17083333333333334, subjectivity=0.17083333333333334),\n",
       " Sentiment(polarity=0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.7),\n",
       " Sentiment(polarity=-0.03749999999999987, subjectivity=0.6833333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.11666666666666665, subjectivity=0.21666666666666667),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.27499999999999997, subjectivity=0.55),\n",
       " Sentiment(polarity=0.25, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=-0.15, subjectivity=0.8),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.3465714285714286, subjectivity=0.5727619047619047),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=1.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.9, subjectivity=0.65),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.39999999999999997, subjectivity=0.8),\n",
       " Sentiment(polarity=-0.375, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0625, subjectivity=0.5),\n",
       " Sentiment(polarity=0.3125, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.16875, subjectivity=0.32500000000000007),\n",
       " Sentiment(polarity=0.4000000000000001, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.15625, subjectivity=0.34375),\n",
       " Sentiment(polarity=0.4, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.48333333333333334, subjectivity=0.5166666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.4),\n",
       " Sentiment(polarity=-0.4374999999999999, subjectivity=0.4208333333333333),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=0.29999999999999993),\n",
       " Sentiment(polarity=0.11489898989898989, subjectivity=0.5472222222222222),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.4),\n",
       " Sentiment(polarity=0.1875, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.5),\n",
       " Sentiment(polarity=0.13333333333333333, subjectivity=0.35000000000000003),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=-0.375, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.05000000000000001, subjectivity=0.2333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.3333333333333333, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.5),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.16666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.7000000000000001, subjectivity=0.7999999999999999),\n",
       " Sentiment(polarity=0.25, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.41250000000000003, subjectivity=0.7958333333333334),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.4, subjectivity=0.8),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=-0.05, subjectivity=0.5249999999999999),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=3.700743415417188e-17, subjectivity=0.7555555555555555),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.625, subjectivity=0.5),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.05, subjectivity=0.35),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.4, subjectivity=0.4083333333333333),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.6),\n",
       " Sentiment(polarity=0.6666666666666666, subjectivity=0.46666666666666673),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.27999999999999997, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.75, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.06666666666666667, subjectivity=0.03333333333333333),\n",
       " Sentiment(polarity=-0.7142857142857143, subjectivity=0.8571428571428571),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.625, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.35833333333333334, subjectivity=0.625),\n",
       " Sentiment(polarity=0.61875, subjectivity=0.675),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.828125, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2857142857142857, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.25, subjectivity=0.25),\n",
       " Sentiment(polarity=-0.1, subjectivity=0.1),\n",
       " Sentiment(polarity=0.15000000000000002, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.1, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.021212121212121165, subjectivity=0.5555555555555555),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.375, subjectivity=0.1),\n",
       " Sentiment(polarity=0.25, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.4),\n",
       " Sentiment(polarity=0.25, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.3352272727272727, subjectivity=0.5272727272727272),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.35185185185185186),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.39999999999999997, subjectivity=0.25555555555555554),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.1, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.06666666666666667, subjectivity=0.03333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.17045454545454544, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.75),\n",
       " Sentiment(polarity=-0.16666666666666666, subjectivity=0.5833333333333333),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.06666666666666661, subjectivity=0.38888888888888884),\n",
       " Sentiment(polarity=0.75, subjectivity=1.0),\n",
       " Sentiment(polarity=0.75, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.5666666666666667),\n",
       " Sentiment(polarity=0.1875, subjectivity=0.45),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.23333333333333336, subjectivity=0.2569444444444444),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.04999999999999999, subjectivity=0.95),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.15000000000000002, subjectivity=0.35),\n",
       " Sentiment(polarity=0.2333333333333333, subjectivity=0.3),\n",
       " Sentiment(polarity=0.109375, subjectivity=0.875),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.5428571428571429, subjectivity=0.6178571428571429),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.9),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.24318181818181817, subjectivity=0.575),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.06875, subjectivity=0.45625),\n",
       " Sentiment(polarity=0.3, subjectivity=0.39722222222222225),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.75, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3571428571428571, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.125, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.7999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=0.09999999999999999, subjectivity=0.7999999999999999),\n",
       " Sentiment(polarity=0.06818181818181818, subjectivity=0.22727272727272727),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.6, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.22708333333333333, subjectivity=0.7916666666666666),\n",
       " Sentiment(polarity=0.5, subjectivity=0.8888888888888888),\n",
       " Sentiment(polarity=0.15625, subjectivity=0.84375),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.25, subjectivity=0.3),\n",
       " Sentiment(polarity=0.5, subjectivity=0.8888888888888888),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.0029761904761904934, subjectivity=0.5386904761904762),\n",
       " Sentiment(polarity=0.1, subjectivity=0.6),\n",
       " Sentiment(polarity=0.19999999999999998, subjectivity=0.3666666666666667),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2857142857142857, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=-0.08333333333333333, subjectivity=0.21666666666666667),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.375, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.125, subjectivity=1.0),\n",
       " Sentiment(polarity=0.15, subjectivity=0.45),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2676136363636364, subjectivity=0.48863636363636365),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.35),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.005859375, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.2453125, subjectivity=0.7),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=-0.125, subjectivity=0.75),\n",
       " Sentiment(polarity=-0.3125, subjectivity=0.25),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.75, subjectivity=1.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.9),\n",
       " Sentiment(polarity=-0.375, subjectivity=1.0),\n",
       " Sentiment(polarity=0.41818181818181815, subjectivity=0.5272727272727273),\n",
       " Sentiment(polarity=0.68359375, subjectivity=0.65),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=1.0, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.04166666666666667, subjectivity=0.25),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.04999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.390625, subjectivity=0.6875),\n",
       " Sentiment(polarity=0.41818181818181815, subjectivity=0.5272727272727273),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.15000000000000002, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.05),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.625, subjectivity=0.5),\n",
       " Sentiment(polarity=0.6000000000000001, subjectivity=0.625),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.32499999999999996, subjectivity=0.5),\n",
       " Sentiment(polarity=0.5666666666666667, subjectivity=0.6),\n",
       " Sentiment(polarity=-1.0, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=-0.5, subjectivity=0.29999999999999993),\n",
       " Sentiment(polarity=0.45, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4861111111111111, subjectivity=0.8333333333333334),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5375),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3125, subjectivity=0.8500000000000001),\n",
       " Sentiment(polarity=0.23958333333333337, subjectivity=0.49166666666666675),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.625, subjectivity=0.9),\n",
       " Sentiment(polarity=0.39999999999999997, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.3621212121212121, subjectivity=0.5515151515151515),\n",
       " Sentiment(polarity=0.5, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.6071428571428572, subjectivity=0.9285714285714286),\n",
       " Sentiment(polarity=0.05000000000000001, subjectivity=0.3583333333333333),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.590625, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.6, subjectivity=0.9),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.21875, subjectivity=0.45),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=-0.2, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.7999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.33333333333333337, subjectivity=0.41666666666666663),\n",
       " Sentiment(polarity=0.1, subjectivity=0.1),\n",
       " Sentiment(polarity=0.654296875, subjectivity=0.625),\n",
       " Sentiment(polarity=0.0, subjectivity=0.16666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2611742424242424, subjectivity=0.6212752525252525),\n",
       " Sentiment(polarity=0.3604166666666666, subjectivity=0.4833333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=0.3333333333333333, subjectivity=0.5),\n",
       " Sentiment(polarity=0.30000000000000004, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.65, subjectivity=0.675),\n",
       " Sentiment(polarity=0.71875, subjectivity=0.7),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.25),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.68359375, subjectivity=0.65),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.7999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.8499999999999999, subjectivity=0.8333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.15, subjectivity=0.1),\n",
       " Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.5, subjectivity=0.8888888888888888),\n",
       " Sentiment(polarity=0.012121212121212116, subjectivity=0.38484848484848483),\n",
       " Sentiment(polarity=0.35, subjectivity=0.30000000000000004),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6190476190476191, subjectivity=0.6285714285714286),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.1875, subjectivity=0.9444444444444444),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.0390625, subjectivity=0.21666666666666667),\n",
       " Sentiment(polarity=0.4, subjectivity=0.35),\n",
       " Sentiment(polarity=-1.0, subjectivity=0.8571428571428571),\n",
       " Sentiment(polarity=-0.375, subjectivity=0.875),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.375),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.03333333333333333),\n",
       " Sentiment(polarity=0.5484848484848485, subjectivity=0.7848484848484848),\n",
       " Sentiment(polarity=0.65, subjectivity=0.6),\n",
       " Sentiment(polarity=0.14545454545454545, subjectivity=0.4515151515151515),\n",
       " Sentiment(polarity=0.375, subjectivity=0.925),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.05000000000000001, subjectivity=0.6444444444444445),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3416666666666666, subjectivity=0.39999999999999997),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.55),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.2130681818181818, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.875, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=-0.255859375, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.12499999999999997, subjectivity=0.85),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.8),\n",
       " Sentiment(polarity=1.0, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=-0.1, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.75),\n",
       " Sentiment(polarity=0.3125, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3571428571428571, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.15476190476190477, subjectivity=0.6190476190476191),\n",
       " Sentiment(polarity=0.75, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.790625, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.75, subjectivity=0.675),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.625, subjectivity=0.8888888888888888),\n",
       " Sentiment(polarity=0.17045454545454544, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.390625, subjectivity=0.30000000000000004),\n",
       " Sentiment(polarity=0.55, subjectivity=0.39999999999999997),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.18465909090909088, subjectivity=0.42727272727272725),\n",
       " Sentiment(polarity=0.15, subjectivity=0.13333333333333333),\n",
       " Sentiment(polarity=0.4166666666666667, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6160714285714286, subjectivity=0.5857142857142857),\n",
       " Sentiment(polarity=0.8, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.6125, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.2, subjectivity=0.4),\n",
       " Sentiment(polarity=-0.15, subjectivity=0.44999999999999996),\n",
       " Sentiment(polarity=0.625, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.5, subjectivity=0.29999999999999993),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.65, subjectivity=0.6),\n",
       " Sentiment(polarity=1.0, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.4),\n",
       " Sentiment(polarity=0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.35714285714285715, subjectivity=0.9285714285714286),\n",
       " Sentiment(polarity=1.0, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.125, subjectivity=0.8),\n",
       " Sentiment(polarity=-0.6375, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.25, subjectivity=0.25),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666),\n",
       " Sentiment(polarity=0.3, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6083333333333333, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.8, subjectivity=0.9),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=0.25, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2604166666666667, subjectivity=0.18888888888888888),\n",
       " Sentiment(polarity=-0.11410984848484851, subjectivity=0.49810606060606055),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.03333333333333333, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4008928571428572, subjectivity=0.7142857142857144),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.9375, subjectivity=1.0),\n",
       " Sentiment(polarity=-0.7999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.75),\n",
       " Sentiment(polarity=0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.30000000000000004, subjectivity=0.5666666666666667),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3833333333333333, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=1.0, subjectivity=0.75),\n",
       " Sentiment(polarity=0.7, subjectivity=0.85),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.25, subjectivity=0.5),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.590625, subjectivity=0.95),\n",
       " Sentiment(polarity=0.5, subjectivity=0.3666666666666667),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.4),\n",
       " Sentiment(polarity=0.8, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.6, subjectivity=0.6833333333333332),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.39999999999999997, subjectivity=0.45),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.22443181818181818, subjectivity=0.37727272727272726),\n",
       " Sentiment(polarity=0.6, subjectivity=0.3),\n",
       " Sentiment(polarity=0.1, subjectivity=0.1),\n",
       " Sentiment(polarity=-0.1625, subjectivity=0.7),\n",
       " Sentiment(polarity=0.7, subjectivity=0.9),\n",
       " Sentiment(polarity=-0.05, subjectivity=0.4),\n",
       " Sentiment(polarity=0.9765625, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.0625, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.25, subjectivity=0.6499999999999999),\n",
       " Sentiment(polarity=0.4, subjectivity=0.8),\n",
       " Sentiment(polarity=-0.625, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.03125, subjectivity=0.75),\n",
       " Sentiment(polarity=0.375, subjectivity=0.2),\n",
       " Sentiment(polarity=0.6103515625, subjectivity=0.2),\n",
       " Sentiment(polarity=-0.7999999999999999, subjectivity=1.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.5),\n",
       " Sentiment(polarity=0.2857142857142857, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.26666666666666666, subjectivity=0.6166666666666667),\n",
       " Sentiment(polarity=-0.09999999999999999, subjectivity=0.4666666666666666),\n",
       " Sentiment(polarity=1.0, subjectivity=0.6),\n",
       " Sentiment(polarity=0.1, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.9),\n",
       " Sentiment(polarity=0.25, subjectivity=0.5),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.75, subjectivity=0.95),\n",
       " Sentiment(polarity=-0.3125, subjectivity=0.25),\n",
       " Sentiment(polarity=-0.16666666666666666, subjectivity=0.8333333333333333),\n",
       " Sentiment(polarity=0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.35, subjectivity=0.30000000000000004),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.9765625, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=1.0),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.45, subjectivity=0.7),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.3333333333333333),\n",
       " Sentiment(polarity=0.0625, subjectivity=0.9444444444444444),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6944444444444444),\n",
       " Sentiment(polarity=0.012499999999999997, subjectivity=0.225),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.5020833333333333, subjectivity=0.48333333333333334),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.05, subjectivity=0.05),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.25, subjectivity=0.3),\n",
       " Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.1, subjectivity=0.4),\n",
       " Sentiment(polarity=0.30625, subjectivity=0.95),\n",
       " Sentiment(polarity=-0.375, subjectivity=0.55),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4333333333333333, subjectivity=0.7333333333333333),\n",
       " Sentiment(polarity=0.5, subjectivity=0.5),\n",
       " Sentiment(polarity=0.640625, subjectivity=0.5),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.1, subjectivity=0.07083333333333333),\n",
       " Sentiment(polarity=-0.16666666666666663, subjectivity=0.7555555555555555),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.35),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.75),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.2),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.8),\n",
       " Sentiment(polarity=0.575, subjectivity=0.6749999999999999),\n",
       " Sentiment(polarity=-0.21875, subjectivity=0.175),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.75, subjectivity=0.55),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5619047619047618, subjectivity=0.6452380952380953),\n",
       " Sentiment(polarity=0.6166666666666667, subjectivity=0.8833333333333333),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.16666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.5, subjectivity=1.0),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.35, subjectivity=0.65),\n",
       " Sentiment(polarity=0.7125, subjectivity=0.6),\n",
       " Sentiment(polarity=0.6, subjectivity=0.9),\n",
       " Sentiment(polarity=-0.004761904761904763, subjectivity=0.4785714285714286),\n",
       " Sentiment(polarity=0.0, subjectivity=0.75),\n",
       " Sentiment(polarity=0.625, subjectivity=0.6),\n",
       " Sentiment(polarity=-0.45, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.375),\n",
       " Sentiment(polarity=0.6, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.5),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.29999999999999993, subjectivity=0.5333333333333333),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.375, subjectivity=0.55),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.4, subjectivity=0.6),\n",
       " Sentiment(polarity=0.25, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.1, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=1.0, subjectivity=0.75),\n",
       " Sentiment(polarity=-0.14583333333333334, subjectivity=0.5208333333333333),\n",
       " Sentiment(polarity=0.75, subjectivity=0.44999999999999996),\n",
       " Sentiment(polarity=0.9, subjectivity=0.7),\n",
       " Sentiment(polarity=-0.3125, subjectivity=0.6875),\n",
       " Sentiment(polarity=0.0, subjectivity=0.06666666666666667),\n",
       " Sentiment(polarity=-0.3, subjectivity=0.4),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.9666666666666667),\n",
       " Sentiment(polarity=0.4, subjectivity=0.39999999999999997),\n",
       " Sentiment(polarity=-0.2976190476190476, subjectivity=0.2857142857142857),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.5, subjectivity=0.6),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.1875, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.3, subjectivity=0.30833333333333335),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.25),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.625, subjectivity=1.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.7, subjectivity=0.6000000000000001),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.8, subjectivity=0.7),\n",
       " Sentiment(polarity=-0.07291666666666667, subjectivity=0.8854166666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.25, subjectivity=0.8166666666666667),\n",
       " Sentiment(polarity=0.19999999999999998, subjectivity=0.73),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=-0.125, subjectivity=0.7250000000000001),\n",
       " Sentiment(polarity=1.0, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.2, subjectivity=0.3),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.4, subjectivity=0.9),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0625, subjectivity=0.5),\n",
       " Sentiment(polarity=0.2857142857142857, subjectivity=0.5357142857142857),\n",
       " Sentiment(polarity=0.3875, subjectivity=0.39999999999999997),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.1),\n",
       " Sentiment(polarity=0.5625, subjectivity=0.8),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.16666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.16666666666666666, subjectivity=0.6666666666666666),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " Sentiment(polarity=0.0, subjectivity=0.0),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_textodef(data)\n",
    "print(data)\n",
    "clasificador(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "340170e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           ` respond , go\n",
       "1                            sooo sad miss san diego ! ! !\n",
       "2                                           boss bulli ...\n",
       "3                                    interview ! leav alon\n",
       "4                   son * * * , ` put relea alreadi bought\n",
       "                               ...                        \n",
       "27476     wish we could come see u on Denver  husband l...\n",
       "27477     I`ve wondered about rake to.  The client has ...\n",
       "27478     Yay good for both of you. Enjoy the break - y...\n",
       "27479                           But it was worth it  ****.\n",
       "27480       All this flirting going on - The ATG smiles...\n",
       "Name: text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be6c34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_textovicente2(dataset):\n",
    "    dataset = dataset.astype(str)\n",
    "    for n in range(len(dataset)):\n",
    "        texto_limpio = re.sub(r\"@\\w+|#\\w+|https?://\\S+|www\\.\\S+\",\"\", dataset['text'].iloc[n])\n",
    "        texto_minusculas = texto_limpio.lower()\n",
    "        tokenizer = TweetTokenizer()\n",
    "        texto_separado = tokenizer.tokenize(texto_minusculas)\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        texto_filtrado = [palabra for palabra in texto_separado if palabra not in stop_words]\n",
    "        \n",
    "        lematizacion = SnowballStemmer(\"english\")\n",
    "        lexemas = [lematizacion.stem(palabra) for palabra in texto_filtrado]\n",
    "        \n",
    "        texto_final = \" \".join(lexemas)\n",
    "        dataset.at[n, 'text'] = texto_final\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c060cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boss bulli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interview ! leav alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>son * * * , ` put releas alreadi bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sooo sad miss san diego ! ! !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1                                     boss bulli ...\n",
       "2                              interview ! leav alon\n",
       "3            son * * * , ` put releas alreadi bought\n",
       "4   Sons of ****, why couldn`t they put them on t...\n",
       "0                      sooo sad miss san diego ! ! !"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_textovicente2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2961d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1      Sooo SAD I will miss you here in San Diego!!!\n",
       "2                          my boss is bullying me...\n",
       "3                     what interview! leave me alone\n",
       "4   Sons of ****, why couldn`t they put them on t..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
