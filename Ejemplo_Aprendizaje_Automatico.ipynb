{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Aprendizaje automático (Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inteligencia Artificial\n",
    "### Universidad de Sevilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Scikit-Learn**, abreviado como `sklearn`, se ha establecido como una piedra angular en el ecosistema de herramientas de aprendizaje automático en Python. Este paquete open-source, desarrollado por un conjunto de expertos en aprendizaje automático, proporciona una interfaz simple y eficiente para la implementación de algoritmos de aprendizaje supervisado y no supervisado, así como herramientas para evaluar y ajustar modelos. Desde su inicio, sklearn ha sido reconocido por su enfoque coherente y su énfasis en la usabilidad, haciendo que la construcción y experimentación con modelos de aprendizaje automático sea accesible para desarrolladores y científicos de datos por igual.\n",
    "\n",
    "Para ilustrar el concepto de aprendizaje supervisado vamos a usar el conjunto de datos [_Car Evaluation_](http://archive.ics.uci.edu/ml/datasets/Car+Evaluation) del repositorio [UCI](http://archive.ics.uci.edu/ml/). Este conjunto de datos contiene información acerca de la idoneidad de una serie de coches, en función de los siguientes atributos discretos:\n",
    "* _buying_: precio de compra. Posibles valores: `vhigh`, `high`, `med`, `low`.\n",
    "* _maint_: coste de mantenimiento. Posibles valores: `vhigh`, `high`, `med`, `low`.\n",
    "* _doors_: número de puertas. Posibles valores: `2`, `3`, `4`, `5more`.\n",
    "* _persons_: número de asientos. Posibles valores: `2`, `4`, `more`.\n",
    "* _lug\\_boot_: tamaño del maletero. Posibles valores: `small`, `med`, `big`.\n",
    "* _safety_: nivel de seguridad estimada. Posibles valores: `low`, `med`, `high`.\n",
    "\n",
    "La idoneidad de cada coche se indica mediante _acceptability_, que los clasifica como `unacc`, `acc`, `good` o `vgood`. Este será nuestro objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer los datos desde el fichero `cars.csv` que se proporciona se pueden evaluar las siguientes expresiones ([_Pandas_](http://pandas.pydata.org/) y [_NumPy_](http://www.numpy.org/) son paquetes de _Python_ para análisis de datos y cálculo científico, respectivamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cars = pandas.read_csv('cars.csv', header=None,\n",
    "                       names=['buying', 'maint', 'doors', 'persons',\n",
    "                              'lug_boot', 'safety', 'acceptability'])\n",
    "\n",
    "# En general, si no se dice nada siempre se va a referir a las columnas, como en names.\n",
    "# Si el archivo no se encuentra en la misma carpeta, se pone como /data/cars.csv por ej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 7)\n"
     ]
    }
   ],
   "source": [
    "# Número de filas y columnas\n",
    "# dim (tabla) en R\n",
    "\n",
    "print(cars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc\n",
       "5  vhigh  vhigh     2       2      med   high         unacc\n",
       "6  vhigh  vhigh     2       2      big    low         unacc\n",
       "7  vhigh  vhigh     2       2      big    med         unacc\n",
       "8  vhigh  vhigh     2       2      big   high         unacc\n",
       "9  vhigh  vhigh     2       4    small    low         unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las 10 primeras filas\n",
    "# head (tabla) en R. \n",
    "cars.head(10)\n",
    "\n",
    "# RECORDAR que en python se empieza desde 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ no puede trabajar directamente con el conjunto de datos anterior, ya que asume que los valores de las variables discretas están codificadas con números enteros. Para transformar los datos a un formato adecuado ofrece diversas operaciones de preprocesamiento, entre las que se encuentran `OrdinalEncoder`, para codificar los atributos discretos a numéricos, y `LabelEncoder`, para codificar la variable objetivo de discreta a númerico.\n",
    "\n",
    "Existen muchas codificadores, hay que encontrar el adecuado para tus datos, por ejemplo para procesamiento de texto natural se suele utilizar `CountVectorizer()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "atributos = cars.loc[:, 'buying':'safety']  # selección de las columnas de atributos\n",
    "# : todas las filas, y todas las columnas que vayan desde buying hasta safety. Accedemos a un número de filas y\n",
    "# columnas en concreto. \n",
    "# . loc es porque le estoy dando una localización concreta, como si le doy unas coordenadas. \n",
    "\n",
    "objetivo = cars['acceptability']  # selección de la columna objetivo, debe ser el resultado de la clasificacion\n",
    "\n",
    "# en R era cars[[\"acceptability\"]] para entrar en una columna entera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['high', 'low', 'med', 'vhigh'], dtype=object), array(['high', 'low', 'med', 'vhigh'], dtype=object), array(['2', '3', '4', '5more'], dtype=object), array(['2', '4', 'more'], dtype=object), array(['big', 'med', 'small'], dtype=object), array(['high', 'low', 'med'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Para realizar una codificación de los datos, se crea una instancia del tipo de\n",
    "# codificación pretendida y se ajusta a los datos disponibles mediante el método fit.\n",
    "\n",
    "#Primero crear la instancia del modelo y luego se entrena. \n",
    "\n",
    "# El codificador adecuado para los atributos es OrdinalEncoder, ya que permite\n",
    "# trabajar con el array completo de valores de los atributos.\n",
    "codificador_atributos = preprocessing.OrdinalEncoder() # Codificar.\n",
    "codificador_atributos.fit(atributos) # Lo entreno para que sea capaz de clasificar los atributos que le doy. \n",
    "\n",
    "# Categorías detectadas por el codificador para cada atributo\n",
    "print(codificador_atributos.categories_)\n",
    "# cada una de las clasificaciones las pilla y las pasa a números. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 0. 0. 2. 1.]\n",
      " [3. 3. 0. 0. 2. 2.]\n",
      " [3. 3. 0. 0. 2. 0.]\n",
      " ...\n",
      " [1. 1. 3. 2. 0. 1.]\n",
      " [1. 1. 3. 2. 0. 2.]\n",
      " [1. 1. 3. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Una vez ajustado el codificador, el método transform permite codificar los\n",
    "# valores de los atributos\n",
    "atributos_codificados = codificador_atributos.transform(atributos)\n",
    "print(atributos_codificados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# El codificador adecuado para la variable objetivo es LabelEncoder, que trabaja\n",
    "# con una lista o array unidimensional de sus valores\n",
    "codificador_objetivo = preprocessing.LabelEncoder()\n",
    "\n",
    "# El método fit_transform ajusta la codificación y la aplica a los datos justo\n",
    "# a continuación\n",
    "objetivo_codificado = codificador_objetivo.fit_transform(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez codificadas las variables, es necesario separar el conjunto de datos en dos: un conjunto de entrenamiento, que se usará para construir los distintos modelos; y un conjunto de prueba, que se usará para comparar los distintos modelos.\n",
    "\n",
    "Un detalle a tener en cuenta es que la distribución de ejemplos en las distintas clases de aceptabilidad no es uniforme: hay 1210 coches (un 70.023&nbsp;% del total) clasificados como inaceptables (`unacc`), 384 coches (22.222&nbsp;%) clasificados como aceptables (`acc`), 69 coches (3.993&nbsp;%) clasificados como buenos (`good`) y 65 coches (3.762&nbsp;%) clasificados como muy buenos (`vgood`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptability\n",
      "unacc    0.700231\n",
      "acc      0.222222\n",
      "good     0.039931\n",
      "vgood    0.037616\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Frecuencia total de cada clase de aceptabilidad\n",
    "print(pandas.Series(objetivo).value_counts(normalize=True))\n",
    "\n",
    "# panda y numpys son paquetes muy grandes. Solo nos pide que aprendamos a leer tablas y a usar los datos. \n",
    "# para ver la freq total. \n",
    "# con pandas accedemos a nuestra variable de objetivo, accedo a esa columna y sigue siendo una tabla de una\n",
    "# sola cloumna, no como en R que se convertía en R. \n",
    "\n",
    "# value_counts es como el table de R -> freq abs dentro de una tabla. \n",
    "# Combinando estas dos funciones nos da la freq rel.\n",
    "# las clasificaciones me las da el series y las freq abs me las da el value_counts. \n",
    "# Ya sabemos que esta es la proporción que tenemos que seguir en nuestros conjuntos de datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es conveniente, por tanto, que la separación de los ejemplos se realice de manera estratificada, es decir, intentando mantener la proporción anterior tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "Para dividir un conjunto de datos en un subconjunto de entrenamiento y otro de prueba, _sklearn_ proporciona la función `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Esto sirve para separar los conjuntos de datos manteniendo las proporciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributos_codificados, objetivo_codificado,\n",
    "        # Valor de la semilla aleatoria, para que el muestreo sea reproducible,\n",
    "        # a pesar de ser aleatorio\n",
    "        # Muestreo aleatorio dentro de nuestro data set. Normalmente se pone una semilla súper alta. \n",
    "        random_state=12345,\n",
    "        # Tamaño del conjunto de prueba, en cuanto queremos dividir nuestro data set original.\n",
    "        # Le estoy diciendo que quiero que el 33% me lo guarde para pruebas. \n",
    "        test_size=.33,\n",
    "        # Estratificamos respecto a la distribución de valores en la variable objetivo\n",
    "        stratify=objetivo_codificado) # Siguiendo siempre estas proporciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos de pruebas requeridos: 570.24\n",
      "Filas del array de atributos de prueba: 571\n",
      "Longitud del vector de objetivos de prueba: 571\n",
      "Proporción de clases en el vector de objetivos de prueba:\n",
      "unacc    0.700525\n",
      "acc      0.222417\n",
      "good     0.040280\n",
      "vgood    0.036778\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que el conjunto de prueba contiene el 33 % de los datos, en la misma proporción\n",
    "# con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de pruebas requeridos:', 1728 * .33)\n",
    "print('Filas del array de atributos de prueba:', atributos_prueba.shape[0])\n",
    "print('Longitud del vector de objetivos de prueba:', len(objetivo_prueba))\n",
    "print('Proporción de clases en el vector de objetivos de prueba:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_prueba)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos de entrenamiento requeridos: 1157.76\n",
      "Filas del array de atributos de entrenamiento: 1157\n",
      "Longitud del vector de objetivos de entrenamiento: 1157\n",
      "Proporción de clases en el vector de objetivos de entrenamiento:\n",
      "unacc    0.700086\n",
      "acc      0.222126\n",
      "good     0.039758\n",
      "vgood    0.038029\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que el conjunto de entrenamiento contiene el resto de los datos, en la misma\n",
    "# proporción con respecto a la variable objetivo\n",
    "print('Cantidad de ejemplos de entrenamiento requeridos:', 1728 * .67)\n",
    "print('Filas del array de atributos de entrenamiento:', atributos_entrenamiento.shape[0])\n",
    "print('Longitud del vector de objetivos de entrenamiento:', len(objetivo_entrenamiento))\n",
    "print('Proporción de clases en el vector de objetivos de entrenamiento:')\n",
    "print(pandas.Series(\n",
    "        codificador_objetivo.inverse_transform(objetivo_entrenamiento)\n",
    "      ).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar aprendizaje supervisado en _sklearn_, basta crear una instancia de la clase de objetos que implemente el modelo que se quiera utilizar (_naive_ Bayes, árboles de decisión, _kNN_, etc.).\n",
    "\n",
    "Cada una de estas instancias dispondrá de los siguientes métodos:\n",
    "* El método `fit` permite entrenar el modelo, dados __por separado__ el conjunto de ejemplos de entrenamiento y la clase de cada uno de estos ejemplos.\n",
    "* El método `predict` permite clasificar un nuevo ejemplo una vez entrenado el modelo.\n",
    "* El método `score` calcula el rendimiento del modelo, dados __por separado__ el conjunto de ejemplos de prueba y la clase de cada uno de estos ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Naive_ Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ implementa _naive_ Bayes para atributos categóricos mediante instancias de la clase `CategoricalNB`. Para otro tipo de tareas, como la que se presentá más adelante con procesamiento del lenguaje natural, se usa MultinomialNB.\n",
    "\n",
    "Dentro de tu data set cuenta las posiciones y busca. Solo se basa en las estadísticas. Tampoco hace falta saber el trasfondo del modelo pero no viene mal por algún error. \n",
    "\n",
    "Lo dificil de explorar el modelo: tenemos que saber como funcions se modelo. Si queremos ...\n",
    "si usamos otro algoritmo, como el de kn vecinos, tnemeos qeu poner auqui e,l número de vecinos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalNB</label><div class=\"sk-toggleable__content\"><pre>CategoricalNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif_NB = naive_bayes.CategoricalNB(alpha=1.0) # categorical porque estamos trabajando para la categorización. \n",
    "clasif_NB.fit(atributos_entrenamiento, objetivo_entrenamiento) # entrenamos con fit,\n",
    "# con score vemos el porcentaje de acierto. \n",
    "PARA EL EXAMEN - 0,70\n",
    "# Podemos o mejorar el modelo (versión del modelo, como el nombre de ese tio raro o ....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `score` la tasa de acierto (_accuracy_) sobre un conjunto de datos de prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8441330998248686"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif_NB.score(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `predict` devuelve la clase predicha por el modelo para usarlo en un futuro con un nuevo ejemplo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "Solución_01_nueva.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
